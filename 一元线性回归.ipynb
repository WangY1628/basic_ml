{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# 从sklearn中导入波士顿房价数据集\n",
    "boston = load_boston()  # 实例化\n",
    "# boston.keys() 可以查看数据集中包含的项目名\n",
    "# boston.target 即y_i\n",
    "\n",
    "X = boston.data[:, 10]  # 数据集中有很多指标，在这里随便选了一个\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 一元线性回归\n",
    "\n",
    "目标函数：$\\hat{y_i}=ax_i+\\hat{b}$\n",
    "\n",
    "损失函数：$\\Sigma_{i=1}^m(y_i-\\hat{y_i})^2$\n",
    "\n",
    "求参数$a,b$的方法：$a=\\frac{\\Sigma_{i=1}^m(x_i-\\bar{x})(y_i-\\bar{y})}{\\Sigma_{i=1}^m(x_i-\\bar{x})^2}$  ,  $b=\\bar{y}-a\\bar{x}$\n",
    "\n",
    "此处使用波士顿房价数据集进行展示"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(-2.3722481101221096, 66.40921832618511)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分数据集\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  # 划分数据集的函数\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=0)  # 训练集：测试集=8:2，随机数种子为0，其他参数可查阅文档\n",
    "\n",
    "\n",
    "def calculate_a_b(x_train, y_train):\n",
    "    \"\"\"\n",
    "    此函数用于计算 a 和 b 的值\n",
    "    :param x_train: 训练集X\n",
    "    :param y_train: 训练集Y\n",
    "    :return: 系数a和截距b\n",
    "    \"\"\"\n",
    "    x_mean = np.mean(X_train)\n",
    "    y_mean = np.mean(y_train)\n",
    "    a_up = 0.0\n",
    "    a_down = 0.0\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        a_up += (x - x_mean) * (y - y_mean)\n",
    "        a_down += (x - x_mean) ** 2\n",
    "\n",
    "    a = a_up / a_down\n",
    "    return a, y_mean - a * x_mean\n",
    "\n",
    "\n",
    "calculate_a_b(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 完整代码\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self._x_train = None\n",
    "        self._y_train = None\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self._x_train = x_train\n",
    "        self._y_train = y_train\n",
    "        x_mean = np.mean(self._x_train)\n",
    "        y_mean = np.mean(self._y_train)\n",
    "        a_up = 0.0\n",
    "        a_down = 0.0\n",
    "        for x, y in zip(self._x_train, self._y_train):\n",
    "            a_up += (x - x_mean) * (y - y_mean)\n",
    "            a_down += (x - x_mean) ** 2\n",
    "        self.a = a_up / a_down\n",
    "        self.b = y_mean - self.a * x_mean\n",
    "        return self\n",
    "\n",
    "    def _predict(self, x):\n",
    "        return self.a * x + self.b\n",
    "    def predict(self, x_test):\n",
    "        return np.array([self._predict(x) for x in x_test])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([29.33984545, 23.9469072 , 23.9469072 , 22.00544944, 22.00544944,\n       22.00544944, 29.55556297, 29.55556297, 29.55556297, 29.55556297,\n       29.55556297, 29.55556297, 29.55556297, 17.04394626, 17.04394626,\n       17.04394626, 17.04394626, 17.04394626, 17.04394626, 17.04394626,\n       17.04394626, 17.04394626, 17.04394626, 17.04394626, 17.04394626,\n       17.04394626, 17.04394626, 17.04394626, 17.04394626, 17.04394626,\n       17.04394626, 17.04394626, 17.04394626, 17.04394626, 17.04394626,\n       20.92686179, 20.92686179, 20.92686179, 20.92686179, 22.86831956,\n       22.86831956, 23.73118968, 23.73118968, 23.73118968, 23.73118968,\n       23.73118968, 23.73118968, 23.73118968, 23.73118968, 23.73118968,\n       26.1040825 , 26.1040825 , 26.1040825 , 26.1040825 , 16.82822873,\n       23.73118968, 25.02549485, 29.7712805 , 19.84827414, 19.84827414,\n       19.84827414, 19.84827414, 19.84827414, 19.84827414, 22.22116697,\n       27.61410521, 27.61410521, 21.57401438, 21.57401438, 21.57401438,\n       20.92686179, 20.92686179, 20.92686179, 20.92686179, 22.00544944,\n       22.00544944, 22.00544944, 22.00544944, 22.00544944, 22.00544944,\n       21.35829685, 21.35829685, 21.35829685, 21.35829685, 22.4368845 ,\n       22.4368845 , 22.4368845 , 22.4368845 , 23.9469072 , 23.9469072 ,\n       23.9469072 , 23.9469072 , 23.08403709, 23.08403709, 23.08403709,\n       23.51547215, 23.51547215, 23.51547215, 23.51547215, 23.51547215,\n       17.25966379, 17.25966379, 17.25966379, 17.25966379, 17.25966379,\n       17.25966379, 17.25966379, 17.25966379, 17.25966379, 17.25966379,\n       17.25966379, 23.9469072 , 23.9469072 , 23.9469072 , 23.9469072 ,\n       23.9469072 , 23.9469072 , 23.9469072 , 23.9469072 , 23.9469072 ,\n       21.14257932, 21.14257932, 21.14257932, 21.14257932, 21.14257932,\n       21.14257932, 21.14257932, 16.6125112 , 16.6125112 , 16.6125112 ,\n       16.6125112 , 16.6125112 , 16.6125112 , 16.6125112 , 16.6125112 ,\n       16.6125112 , 16.6125112 , 16.6125112 , 16.6125112 , 16.6125112 ,\n       16.6125112 , 16.6125112 , 30.63415062, 30.63415062, 30.63415062,\n       30.63415062, 30.63415062, 30.63415062, 30.63415062, 30.63415062,\n       30.63415062, 30.63415062, 30.63415062, 30.63415062, 30.63415062,\n       30.63415062, 30.63415062, 30.63415062, 30.63415062, 30.63415062,\n       30.63415062, 30.63415062, 30.63415062, 30.63415062, 30.63415062,\n       30.63415062, 30.63415062, 30.63415062, 30.63415062, 30.63415062,\n       30.63415062, 30.63415062, 26.53551756, 26.53551756, 26.53551756,\n       26.53551756, 26.53551756, 26.53551756, 26.53551756, 23.9469072 ,\n       23.9469072 , 23.9469072 , 23.9469072 , 23.9469072 , 23.9469072 ,\n       23.9469072 , 23.9469072 , 29.55556297, 29.55556297, 29.55556297,\n       29.55556297, 29.55556297, 29.55556297, 28.69269286, 28.69269286,\n       31.28130321, 35.16421874, 35.16421874, 35.16421874, 25.67264744,\n       25.67264744, 30.63415062, 30.63415062, 30.63415062, 30.63415062,\n       22.22116697, 22.22116697, 22.22116697, 22.22116697, 22.22116697,\n       22.22116697, 22.22116697, 22.22116697, 22.22116697, 22.22116697,\n       22.22116697, 26.96695262, 26.96695262, 26.96695262, 26.96695262,\n       24.80977732, 24.80977732, 24.80977732, 24.80977732, 24.80977732,\n       24.80977732, 24.80977732, 24.80977732, 24.80977732, 24.80977732,\n       24.80977732, 24.80977732, 24.80977732, 24.80977732, 24.80977732,\n       24.80977732, 24.80977732, 24.80977732, 26.53551756, 26.53551756,\n       26.53551756, 26.53551756, 26.53551756, 26.53551756, 21.14257932,\n       21.14257932, 21.14257932, 21.14257932, 21.14257932, 21.14257932,\n       21.14257932, 21.14257932, 21.14257932, 21.14257932, 26.96695262,\n       26.96695262, 28.04554027, 34.30134863, 34.30134863, 34.30134863,\n       34.30134863, 34.30134863, 34.30134863, 34.30134863, 34.30134863,\n       34.30134863, 34.30134863, 34.30134863, 34.30134863, 22.22116697,\n       22.22116697, 22.22116697, 22.22116697, 22.22116697, 24.37834226,\n       24.37834226, 24.37834226, 24.37834226, 24.37834226, 30.20271556,\n       30.20271556, 30.20271556, 30.20271556, 33.00704345, 29.33984545,\n       29.33984545, 23.08403709, 26.53551756, 26.53551756, 26.53551756,\n       20.92686179, 20.92686179, 20.92686179, 27.82982274, 27.82982274,\n       27.82982274, 27.82982274, 27.82982274, 30.41843309, 30.41843309,\n       30.41843309, 27.61410521, 27.61410521, 27.61410521, 22.65260203,\n       22.65260203, 22.65260203, 22.65260203, 22.65260203, 22.65260203,\n       22.65260203, 22.65260203, 22.65260203, 22.65260203, 22.65260203,\n       22.65260203, 22.65260203, 22.65260203, 22.65260203, 22.65260203,\n       20.06399167, 20.06399167, 20.06399167, 20.06399167, 20.06399167,\n       20.06399167, 20.06399167, 20.06399167, 25.88836497, 25.88836497,\n       25.88836497, 25.88836497, 25.88836497, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 28.90841039, 28.04554027, 24.37834226, 24.37834226,\n       21.78973191, 21.78973191, 23.73118968, 25.67264744, 19.84827414,\n       19.84827414, 22.86831956, 22.86831956, 25.67264744, 14.88677096,\n       14.88677096, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.76968649, 18.76968649,\n       18.76968649, 18.76968649, 18.76968649, 18.98540402, 18.98540402,\n       18.98540402, 18.98540402, 18.98540402, 20.92686179, 20.92686179,\n       20.92686179, 20.92686179, 20.92686179, 20.92686179, 20.92686179,\n       20.92686179, 17.04394626, 17.04394626, 17.04394626, 17.04394626,\n       17.04394626])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 试一下\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "lr.predict(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}